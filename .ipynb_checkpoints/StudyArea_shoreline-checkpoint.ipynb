{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EO4SD SHORELINE CHANGE MAPPING AND FORECASTING\n",
    "\n",
    "This code has been modifed by Carpenter (2020) for the project Earth Observation for Sustainable Development. Below demonstrates an example processing workflow for Benin and Togo's Coastline between 2000-2020.\n",
    "\n",
    "This software is based on scripts and code developed by:\n",
    "* Vos K., Splinter K.D., Harley M.D., Simmons J.A., Turner I.L. (2019). CoastSat: a Google Earth Engine-enabled Python toolkit to extract shorelines from publicly available satellite imagery. Environmental Modelling and Software. 122, 104528. https://doi.org/10.1016/j.envsoft.2019.104528\n",
    "\n",
    "It enables the users to extract time-series of shoreline change over the last 20+ years at their site of interest.\n",
    "There are three main steps:\n",
    "1. Retrieval of median composite satellite images of the region of interest from Google Earth Engine\n",
    "2. Shoreline extraction at sub-pixel resolution\n",
    "\n",
    "## Initial settings\n",
    "\n",
    "Refer to the Set-up and Installation section of the User Handbook for instructions on how to install the Python packages necessary to run the software, including Google Earth Engine Python API. See original methodology via https://github.com/kvos/CoastSat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from coastsat import SDS_download, SDS_preprocess, SDS_shoreline, SDS_tools, SDS_transects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieval of the images from GEE\n",
    "\n",
    "The jupyter notebook is where you can customise the processing to your needs. Here, we use an example in Senegal. The  - i.e. boundaries of study area and time, the following variables are required:\n",
    "\n",
    "1. `Coordinate_List`- list of the coordinates of the region of interest (longitude/latitude pairs in WGS84) - see below for an example of how to extract ROI coordinates\n",
    "2. `All_dates` - dates over which the images will be retrieved (e.g., `dates = ['2017-12-01', '2018-01-01']`)\n",
    "3. `All_sats`: satellite missions to consider (e.g., `sat_list = ['L7', 'L8', 'S2']` for Landsat 7, 8 and Sentinel-2 collections).\n",
    "\n",
    "        FYI.    Landsat 5 = 1984-01-01 - 2012-05-05 (Limited Coverage in some areas)\n",
    "                Landsat 7 = January 1999 - Present\n",
    "                Landsat 8 = April 2013 - Present\n",
    "                Sentinel 2 = 2015-06-23 â€“ Present\n",
    "\n",
    "4. `Sitename`: name of the site (this is the name of the subfolder where the images and other accompanying files will be stored)\n",
    "5. `Settings`: Some of the settings mimic the original. Here are the added parameters:\n",
    "    1. `Output_epsg` = Country-specific coordinate system (see https://epsg.io/)\n",
    "    2. `coregistration` = True/False\n",
    "    3. Image Download parameters to refine cloud thresholds, merge Landsat satellites and shadow thresholds in Sentinel 2 \n",
    "        \n",
    "There are additional parameters (`min_beach_size`, `buffer_size`, `min_length_sl`, `cloud_mask_issue` and `sand_color`) that can be tuned to optimise the shoreline detection in a specific area.\n",
    "\n",
    "Similar to coastsat, there are some extra parameters such as those to go through manual checking, whether to combine Landsat collections and cloud thresholds.\n",
    "\n",
    "Make sure the area of your ROI is smaller than 100 km2 (if larger split it into smaller ROIs) - GEE limits download size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images available between 2011-01-01 and 2011-12-31:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "  L7: 12 images\n",
      "\n",
      "Downloading images:\n",
      "- Cloud minimal images in Median:\n",
      "   L7: 11\n",
      "   Total: 11\n",
      "Median Processed\n",
      "Landsat co-registration (slave) image cloud cover:  0.02\n",
      "Sentinel co-registration (master) image cloud cover:  0.091105\n",
      "Co-registered\n",
      "Downloaded\n",
      "\n",
      "Images available between 2020-01-01 and 2020-12-31:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "  L8: 21 images\n",
      "\n",
      "Downloading images:\n",
      "- Cloud minimal images in Median:\n",
      "   L8: 13\n",
      "   Total: 13\n",
      "Median Processed\n",
      "Landsat co-registration (slave) image cloud cover:  0.02\n",
      "Sentinel co-registration (master) image cloud cover:  0.091105\n",
      "Co-registered\n",
      "Downloaded\n",
      "\n",
      "Mapping shorelines:\n",
      "L7:   100%\n",
      "L8:   100%\n",
      "Images available between 2011-01-01 and 2011-12-31:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "  L7: 12 images\n",
      "\n",
      "Downloading images:\n",
      "- Cloud minimal images in Median:\n",
      "   L7: 11\n",
      "   Total: 11\n",
      "Median Processed\n",
      "Landsat co-registration (slave) image cloud cover:  0.02\n",
      "Sentinel co-registration (master) image cloud cover:  0.009038\n",
      "Co-registered\n",
      "Downloaded\n",
      "\n",
      "Images available between 2020-01-01 and 2020-12-31:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "  L8: 40 images\n",
      "\n",
      "Downloading images:\n",
      "- Cloud minimal images in Median:\n",
      "   L8: 26\n",
      "   Total: 26\n",
      "Median Processed\n",
      "Landsat co-registration (slave) image cloud cover:  0.02\n",
      "Sentinel co-registration (master) image cloud cover:  0.009038\n",
      "Co-registered\n",
      "Downloaded\n",
      "\n",
      "Mapping shorelines:\n",
      "L7:   100%\n",
      "L8:   100%\n"
     ]
    }
   ],
   "source": [
    "coordinate_list =([[-16.6846408943336,15.5168999353628],[-16.6846408943336,15.4244383075644],[-16.7575149625457,15.5168999353628],[-16.7575149625457,15.4244383075644]]),\\\n",
    "([[-16.7412674146324,15.4339016442281],[-16.7412674146324,15.3383465601779],[-16.8076000286106,15.4339016442281],[-16.8076000286106,15.3383465601779]]),\\\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for polygon in coordinate_list:\n",
    "\n",
    "# region of interest (longitude, latitude)\n",
    "    polygon = coordinate_list[counter]\n",
    "\n",
    "#IMPORTANT - The code will retrieve the satellite data from the the defined time period and satellite\n",
    "#            dependant on the number in the list. I.e. ['2000-01-01', '2000-12-31'] or all_dates[0]\n",
    "#            corresponds to ['L7'] or all_sats[0]. \n",
    "\n",
    "    all_dates = ([['2011-01-01', '2011-12-31'],['2020-01-01', '2020-12-31']])\n",
    "\n",
    "#IMPORTANT - Be cautious of calculating change statistics using Landat and Sentinel as they\n",
    "#            have different referencing frameworks\n",
    "\n",
    "    all_sats = ([['L7'],['L8']])\n",
    "    \n",
    "    rolling = 0\n",
    "\n",
    "    for dates in all_dates:\n",
    "        # date range\n",
    "        dates = all_dates[rolling]\n",
    "        # satellite missions\n",
    "        sat_list = all_sats[rolling]\n",
    "        # name of the site\n",
    "        foldernumber = counter\n",
    "        sitename = 'Senegal_' + str(foldernumber) \n",
    "        # directory where the data will be stored\n",
    "        filepath = os.path.join(os.getcwd(), 'data')\n",
    "        # put all the inputs into a dictionnary\n",
    "        inputs = {'polygon': polygon, 'dates': dates, 'sat_list': sat_list, 'sitename': sitename, 'filepath': filepath, 'rolling': str(rolling)}\n",
    "\n",
    "        settings = { \n",
    "            # general parameters:\n",
    "            'output_epsg': 32628,        # epsg code of spatial reference system desired for the output\n",
    "            # quality control:\n",
    "            'check_detection': False,    # if True, shows each shoreline detection to the user for validation\n",
    "            'save_figure': False,        # if True, saves a figure showing the mapped shoreline for each image\n",
    "            # add the inputs defined previously\n",
    "            'inputs': inputs,\n",
    "            # [ONLY FOR ADVANCED USERS] shoreline detection parameters:\n",
    "            'min_beach_area': 1000,     # minimum area (in metres^2) for an object to be labelled as a beach\n",
    "            'buffer_size': 150,         # radius (in metres) of the buffer around sandy pixels considered in the shoreline detection\n",
    "            'min_length_sl': 200,       # minimum length (in metres) of shoreline perimeter to be valid\n",
    "            'cloud_mask_issue': False,  # switch this parameter to True if sand pixels are masked (in black) on many images  \n",
    "            'sand_color': 'default',    # 'default', 'dark' (for grey/black sand beaches) or 'bright' (for white sand beaches)\n",
    "            \n",
    "            #Co-registration\n",
    "            'coregistration': True,\n",
    "            \n",
    "            ## Image download Parameters\n",
    "            # Landsat\n",
    "            'LCloudScore': 15,         # Mean cloud score threshold (include images with less then threshold)\n",
    "            'add_L7_to_L5': True,      # Add Landsat 7 to Landsat 5 median composite if they are in same time period\n",
    "            'add_L5_to_L7': False,      # Add Landsat 5 to Landsat 7 median composite if they are in same time period\n",
    "            'add_L7_to_L8': False,      # Add Landsat 7 to Landsat 8 median composite if they are in same time period\n",
    "            'LCloudThreshold': 35,     # Pixels from a single image in a collection larger than this cloud score threshold\n",
    "                                       # will be masked.\n",
    "            # Sentinel\n",
    "            'CLOUD_FILTER': 30,          # [Integer] Maximum image cloud cover percent allowed in image collection'\n",
    "            'CLD_PRB_THRESH': 15,        # {Integer] Cloud probability (%); values greater than are considered cloud\n",
    "            'NIR_DRK_THRESH': 0.08,      # [Float] Near-infrared reflectance; values less than are considered potential cloud shadow\n",
    "            'CLD_PRJ_DIST': 2,           # [Float] Maximum distance (km) to search for cloud shadows from cloud edges |\n",
    "            'BUFFER': 50,               # [Integer] Distance (m) to dilate the edge of cloud-identified objects |\n",
    "            \n",
    "        }\n",
    "\n",
    "        inputs['include_T2'] = False\n",
    "        metadata = SDS_download.retrieve_images(inputs,settings)\n",
    "\n",
    "        metadata = SDS_download.get_metadata(inputs)\n",
    "          \n",
    "        rolling = rolling + 1\n",
    "##Batch shoreline detection\n",
    "    %matplotlib qt\n",
    "    output = SDS_shoreline.extract_shorelines(metadata, settings, inputs)\n",
    "\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
